<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Function reference â€¢ sparklyr</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">


<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>
  
  
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-index">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">sparklyr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="..//index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/deployment-amazon-ec2.html">Spark Standalone Deployment in AWS</a>
    </li>
    <li>
      <a href="../articles/deployment-amazon-emr.html">Using sparklyr with an Apache Spark cluster</a>
    </li>
    <li>
      <a href="../articles/deployment-amazon.html">Deployments to Amazon</a>
    </li>
    <li>
      <a href="../articles/deployment-cdh.html">Using sparklyr with an Apache Spark cluster</a>
    </li>
    <li>
      <a href="../articles/deployment-connections.html">Configuring Spark Connections</a>
    </li>
    <li>
      <a href="../articles/deployment-data-lakes.html">Data Science using a Data Lake</a>
    </li>
    <li>
      <a href="../articles/deployment-overview.html">Deployment and Configuration</a>
    </li>
    <li>
      <a href="../articles/gallery.html">Analyzing Data with sparklyr</a>
    </li>
    <li>
      <a href="../articles/guides-caching.html">Understanding Spark Caching</a>
    </li>
    <li>
      <a href="../articles/guides-distributed-r.html">Distributing R Computations</a>
    </li>
    <li>
      <a href="../articles/guides-dplyr.html">Manipulating Data with dplyr</a>
    </li>
    <li>
      <a href="../articles/guides-extensions.html">Creating Extensions for sparklyr</a>
    </li>
    <li>
      <a href="../articles/guides-h2o.html">Sparkling Water (H2O) Machine Learning</a>
    </li>
    <li>
      <a href="../articles/guides-mllib.html">Spark Machine Learning Library (MLlib)</a>
    </li>
    <li>
      <a href="../articles/guides-textmining.html">Text mining with Spark &amp; sparklyr</a>
    </li>
    <li>
      <a href="../articles/reference-media.html">Media</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="col-md-9">
    <div class="page-header">
      <h1>
        Reference
        <small>version&nbsp;0.7.0-9104</small>
      </h1>
    </div>

    <div class="contents">
      <table class="ref-index">

      <colgroup>
        <col class="alias" />
        <col class="title" />
      </colgroup>

      <tbody>
        <tr>
          <th colspan="2">
            <h2 id="section-all-functions" class="hasAnchor"><a href="#section-all-functions" class="anchor"></a>All functions</h2>
            <p class="section-desc"></p>
          </th>
        </tr>
        <tr>
          <!--  -->
          <td>
            <p><code><a href="checkpoint_directory.html">spark_set_checkpoint_dir</a></code> <code><a href="checkpoint_directory.html">spark_get_checkpoint_dir</a></code> </p>
          </td>
          <td><p>Set/Get Spark checkpoint directory</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="compile_package_jars.html">compile_package_jars</a></code> </p>
          </td>
          <td><p>Compile Scala sources into a Java Archive (jar)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="connection_config.html">connection_config</a></code> </p>
          </td>
          <td><p>Read configuration values for a connection</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="copy_to.spark_connection.html">copy_to</a></code> </p>
          </td>
          <td><p>Copy an R Data Frame to Spark</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="download_scalac.html">download_scalac</a></code> </p>
          </td>
          <td><p>Downloads default Scala Compilers</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ensure.html">ensure_scalar_integer</a></code> <code><a href="ensure.html">ensure_scalar_double</a></code> <code><a href="ensure.html">ensure_scalar_boolean</a></code> <code><a href="ensure.html">ensure_scalar_character</a></code> </p>
          </td>
          <td><p>Enforce Specific Structure for R Objects</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="find_scalac.html">find_scalac</a></code> </p>
          </td>
          <td><p>Discover the Scala Compiler</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_binarizer.html">ft_binarizer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- Binarizer (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_bucketizer.html">ft_bucketizer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- Bucketizer (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_count_vectorizer.html">ft_count_vectorizer</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- CountVectorizer (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_dct.html">ft_dct</a></code> <code><a href="ft_dct.html">ft_discrete_cosine_transform</a></code> </p>
          </td>
          <td><p>Feature Transformation -- Discrete Cosine Transform (DCT) (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_elementwise_product.html">ft_elementwise_product</a></code> </p>
          </td>
          <td><p>Feature Transformation -- ElementwiseProduct (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_hashing_tf.html">ft_hashing_tf</a></code> </p>
          </td>
          <td><p>Feature Transformation -- HashingTF (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_index_to_string.html">ft_index_to_string</a></code> </p>
          </td>
          <td><p>Feature Transformation -- IndexToString (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_one_hot_encoder.html">ft_one_hot_encoder</a></code> </p>
          </td>
          <td><p>Feature Transformation -- OneHotEncoder (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_pca.html">ft_pca</a></code> <code><a href="ft_pca.html">ml_pca</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- PCA (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_quantile_discretizer.html">ft_quantile_discretizer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- QuantileDiscretizer (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_r_formula.html">ft_r_formula</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- RFormula (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_regex_tokenizer.html">ft_regex_tokenizer</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- RegexTokenizer (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_stop_words_remover.html">ft_stop_words_remover</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- StopWordsRemover (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_string_indexer.html">ft_string_indexer</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- StringIndexer (Estimator)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_tokenizer.html">ft_tokenizer</a></code> </p>
          </td>
          <td><p>Feature Tranformation -- Tokenizer (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ft_vector_assembler.html">ft_vector_assembler</a></code> </p>
          </td>
          <td><p>Feature Transformation -- VectorAssembler (Transformer)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="hive_context_config.html">hive_context_config</a></code> </p>
          </td>
          <td><p>Runtime configuration interface for Hive</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="invoke.html">invoke</a></code> <code><a href="invoke.html">invoke_static</a></code> <code><a href="invoke.html">invoke_new</a></code> </p>
          </td>
          <td><p>Invoke a Method on a JVM Object</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="livy_config.html">livy_config</a></code> </p>
          </td>
          <td><p>Create a Spark Configuration for Livy</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="livy_service.html">livy_service_start</a></code> <code><a href="livy_service.html">livy_service_stop</a></code> </p>
          </td>
          <td><p>Start Livy</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml-params.html">ml_is_set</a></code> <code><a href="ml-params.html">ml_param_map</a></code> <code><a href="ml-params.html">ml_param</a></code> <code><a href="ml-params.html">ml_params</a></code> </p>
          </td>
          <td><p>Spark ML -- ML Params</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml-persistence.html">ml_save</a></code> <code><a href="ml-persistence.html">ml_load</a></code> </p>
          </td>
          <td><p>Spark ML -- Model Persistence</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml-transform-methods.html">is_ml_transformer</a></code> <code><a href="ml-transform-methods.html">is_ml_estimator</a></code> <code><a href="ml-transform-methods.html">ml_fit</a></code> <code><a href="ml-transform-methods.html">ml_transform</a></code> <code><a href="ml-transform-methods.html">ml_fit_and_transform</a></code> <code><a href="ml-transform-methods.html">ml_predict</a></code> </p>
          </td>
          <td><p>Spark ML -- Transform, fit, and predict methods (ml_ interface)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml-tuning.html">ml_cross_validator</a></code> <code><a href="ml-tuning.html">ml_train_validation_split</a></code> </p>
          </td>
          <td><p>Spark ML -- Tuning</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_aft_survival_regression.html">ml_aft_survival_regression</a></code> <code><a href="ml_aft_survival_regression.html">ml_survival_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Survival Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_als.html">ml_als</a></code> <code><a href="ml_als.html">ml_recommend</a></code> <code><a href="ml_als.html">ml_als_factorization</a></code> </p>
          </td>
          <td><p>Spark ML -- ALS</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_bisecting_kmeans.html">ml_bisecting_kmeans</a></code> </p>
          </td>
          <td><p>Spark ML -- Bisecting K-Means Clustering</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_decision_tree.html">ml_decision_tree_classifier</a></code> <code><a href="ml_decision_tree.html">ml_decision_tree</a></code> <code><a href="ml_decision_tree.html">ml_decision_tree_regressor</a></code> </p>
          </td>
          <td><p>Spark ML -- Decision Trees</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_default_stop_words.html">ml_default_stop_words</a></code> </p>
          </td>
          <td><p>Default stop words</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_evaluate.html">ml_evaluate</a></code> </p>
          </td>
          <td><p>Spark ML -- Evaluate prediction frames with evaluators</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_evaluator.html">ml_binary_classification_evaluator</a></code> <code><a href="ml_evaluator.html">ml_binary_classification_eval</a></code> <code><a href="ml_evaluator.html">ml_multiclass_classification_evaluator</a></code> <code><a href="ml_evaluator.html">ml_classification_eval</a></code> <code><a href="ml_evaluator.html">ml_regression_evaluator</a></code> </p>
          </td>
          <td><p>Spark ML - Evaluators</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_gaussian_mixture.html">ml_gaussian_mixture</a></code> </p>
          </td>
          <td><p>Spark ML -- Gaussian Mixture clustering.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_generalized_linear_regression.html">ml_generalized_linear_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Generalized Linear Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_glm_tidiers.html">tidy</a></code> <code><a href="ml_glm_tidiers.html">augment</a></code> <code><a href="ml_glm_tidiers.html">glance</a></code> </p>
          </td>
          <td><p>Tidying methods for Spark ML linear models</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_gradient_boosted_trees.html">ml_gbt_classifier</a></code> <code><a href="ml_gradient_boosted_trees.html">ml_gradient_boosted_trees</a></code> <code><a href="ml_gradient_boosted_trees.html">ml_gbt_regressor</a></code> </p>
          </td>
          <td><p>Spark ML -- Gradient Boosted Trees</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_isotonic_regression.html">ml_isotonic_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Isotonic Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_kmeans.html">ml_kmeans</a></code> </p>
          </td>
          <td><p>Spark ML -- K-Means Clustering</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_lda.html">ml_lda</a></code> </p>
          </td>
          <td><p>Spark ML -- Latent Dirichlet Allocation</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_linear_regression.html">ml_linear_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Linear Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_linear_svc.html">ml_linear_svc</a></code> </p>
          </td>
          <td><p>Spark ML -- LinearSVC</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_logistic_regression.html">ml_logistic_regression</a></code> </p>
          </td>
          <td><p>Spark ML -- Logistic Regression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_model_data.html">ml_model_data</a></code> </p>
          </td>
          <td><p>Extracts data associated with a Spark ML model</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_multilayer_perceptron_classifier.html">ml_multilayer_perceptron_classifier</a></code> <code><a href="ml_multilayer_perceptron_classifier.html">ml_multilayer_perceptron</a></code> </p>
          </td>
          <td><p>Spark ML -- Multilayer Perceptron</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_naive_bayes.html">ml_naive_bayes</a></code> </p>
          </td>
          <td><p>Spark ML -- Naive-Bayes</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_one_vs_rest.html">ml_one_vs_rest</a></code> </p>
          </td>
          <td><p>Spark ML -- OneVsRest</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_pipeline.html">ml_pipeline</a></code> </p>
          </td>
          <td><p>Spark ML -- Pipelines</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_random_forest.html">ml_random_forest_classifier</a></code> <code><a href="ml_random_forest.html">ml_random_forest</a></code> <code><a href="ml_random_forest.html">ml_random_forest_regressor</a></code> </p>
          </td>
          <td><p>Spark ML -- Random Forest</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_stage.html">ml_stage</a></code> <code><a href="ml_stage.html">ml_stages</a></code> </p>
          </td>
          <td><p>Spark ML -- Pipeline stage extraction</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_summary.html">ml_summary</a></code> </p>
          </td>
          <td><p>Spark ML -- Extraction of summary metrics</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_tree_feature_importance.html">ml_tree_feature_importance</a></code> </p>
          </td>
          <td><p>Spark ML - Feature Importance for Tree Models</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="ml_uid.html">ml_uid</a></code> </p>
          </td>
          <td><p>Spark ML -- UID</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="na.replace.html">na.replace</a></code> </p>
          </td>
          <td><p>Replace Missing Values in Objects</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="random_string.html">random_string</a></code> </p>
          </td>
          <td><p>Random string generation</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="register_extension.html">register_extension</a></code> <code><a href="register_extension.html">registered_extensions</a></code> </p>
          </td>
          <td><p>Register a Package that Implements a Spark Extension</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf-saveload.html">sdf_save_table</a></code> <code><a href="sdf-saveload.html">sdf_load_table</a></code> <code><a href="sdf-saveload.html">sdf_save_parquet</a></code> <code><a href="sdf-saveload.html">sdf_load_parquet</a></code> </p>
          </td>
          <td><p>Save / Load a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf-transform-methods.html">sdf_predict</a></code> <code><a href="sdf-transform-methods.html">sdf_transform</a></code> <code><a href="sdf-transform-methods.html">sdf_fit</a></code> <code><a href="sdf-transform-methods.html">sdf_fit_and_transform</a></code> </p>
          </td>
          <td><p>Spark ML -- Transform, fit, and predict methods (sdf_ interface)</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_along.html">sdf_along</a></code> </p>
          </td>
          <td><p>Create DataFrame for along Object</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_bind.html">sdf_bind_rows</a></code> <code><a href="sdf_bind.html">sdf_bind_cols</a></code> </p>
          </td>
          <td><p>Bind multiple Spark DataFrames by row and column</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_broadcast.html">sdf_broadcast</a></code> </p>
          </td>
          <td><p>Broadcast hint</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_checkpoint.html">sdf_checkpoint</a></code> </p>
          </td>
          <td><p>Checkpoint a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_coalesce.html">sdf_coalesce</a></code> </p>
          </td>
          <td><p>Coalesces a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_copy_to.html">sdf_copy_to</a></code> <code><a href="sdf_copy_to.html">sdf_import</a></code> </p>
          </td>
          <td><p>Copy an Object into Spark</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_dim.html">sdf_dim</a></code> <code><a href="sdf_dim.html">sdf_nrow</a></code> <code><a href="sdf_dim.html">sdf_ncol</a></code> </p>
          </td>
          <td><p>Support for Dimension Operations</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_last_index.html">sdf_last_index</a></code> </p>
          </td>
          <td><p>Returns the last index of a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_len.html">sdf_len</a></code> </p>
          </td>
          <td><p>Create DataFrame for Length</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_mutate.html">sdf_mutate</a></code> <code><a href="sdf_mutate.html">sdf_mutate_</a></code> </p>
          </td>
          <td><p>Mutate a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_num_partitions.html">sdf_num_partitions</a></code> </p>
          </td>
          <td><p>Gets number of partitions of a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_partition.html">sdf_partition</a></code> </p>
          </td>
          <td><p>Partition a Spark Dataframe</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_persist.html">sdf_persist</a></code> </p>
          </td>
          <td><p>Persist a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_pivot.html">sdf_pivot</a></code> </p>
          </td>
          <td><p>Pivot a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_project.html">sdf_project</a></code> </p>
          </td>
          <td><p>Project features onto principal components</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_quantile.html">sdf_quantile</a></code> </p>
          </td>
          <td><p>Compute (Approximate) Quantiles with a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_read_column.html">sdf_read_column</a></code> </p>
          </td>
          <td><p>Read a Column from a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_register.html">sdf_register</a></code> </p>
          </td>
          <td><p>Register a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_repartition.html">sdf_repartition</a></code> </p>
          </td>
          <td><p>Repartition a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_residuals.html">sdf_residuals</a></code> </p>
          </td>
          <td><p>Model Residuals</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_sample.html">sdf_sample</a></code> </p>
          </td>
          <td><p>Randomly Sample Rows from a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_schema.html">sdf_schema</a></code> </p>
          </td>
          <td><p>Read the Schema of a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_separate_column.html">sdf_separate_column</a></code> </p>
          </td>
          <td><p>Separate a Vector Column into Scalar Columns</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_seq.html">sdf_seq</a></code> </p>
          </td>
          <td><p>Create DataFrame for Range</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_sort.html">sdf_sort</a></code> </p>
          </td>
          <td><p>Sort a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_with_sequential_id.html">sdf_with_sequential_id</a></code> </p>
          </td>
          <td><p>Add a Sequential ID Column to a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sdf_with_unique_id.html">sdf_with_unique_id</a></code> </p>
          </td>
          <td><p>Add a Unique ID Column to a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark-api.html">spark_context</a></code> <code><a href="spark-api.html">java_context</a></code> <code><a href="spark-api.html">hive_context</a></code> <code><a href="spark-api.html">spark_session</a></code> </p>
          </td>
          <td><p>Access the Spark API</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark-connections.html">spark_connect</a></code> <code><a href="spark-connections.html">spark_connection_is_open</a></code> <code><a href="spark-connections.html">spark_disconnect</a></code> <code><a href="spark-connections.html">spark_disconnect_all</a></code> </p>
          </td>
          <td><p>Manage Spark Connections</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_apply.html">spark_apply</a></code> </p>
          </td>
          <td><p>Apply an R Function in Spark</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_apply_bundle.html">spark_apply_bundle</a></code> </p>
          </td>
          <td><p>Create Bundle for Spark Apply</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_apply_log.html">spark_apply_log</a></code> </p>
          </td>
          <td><p>Log Writter for Spark Apply</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_compilation_spec.html">spark_compilation_spec</a></code> </p>
          </td>
          <td><p>Define a Spark Compilation Specification</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_config.html">spark_config</a></code> </p>
          </td>
          <td><p>Read Spark Configuration</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_connection.html">spark_connection</a></code> </p>
          </td>
          <td><p>Retrieve the Spark Connection Associated with an R Object</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_context_config.html">spark_context_config</a></code> </p>
          </td>
          <td><p>Runtime configuration interface for Spark.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_dataframe.html">spark_dataframe</a></code> </p>
          </td>
          <td><p>Retrieve a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_default_compilation_spec.html">spark_default_compilation_spec</a></code> </p>
          </td>
          <td><p>Default Compilation Specification for Spark Extensions</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_dependency.html">spark_dependency</a></code> </p>
          </td>
          <td><p>Define a Spark dependency</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_home_set.html">spark_home_set</a></code> </p>
          </td>
          <td><p>Set the SPARK_HOME environment variable</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_install_sync.html">spark_install_sync</a></code> </p>
          </td>
          <td><p>helper function to sync sparkinstall project to sparklyr</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_jobj.html">spark_jobj</a></code> </p>
          </td>
          <td><p>Retrieve a Spark JVM Object Reference</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_load_table.html">spark_load_table</a></code> </p>
          </td>
          <td><p>Reads from a Spark Table into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_log.html">spark_log</a></code> </p>
          </td>
          <td><p>View Entries in the Spark Log</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_csv.html">spark_read_csv</a></code> </p>
          </td>
          <td><p>Read a CSV file into a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_jdbc.html">spark_read_jdbc</a></code> </p>
          </td>
          <td><p>Read from JDBC connection into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_json.html">spark_read_json</a></code> </p>
          </td>
          <td><p>Read a JSON file into a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_libsvm.html">spark_read_libsvm</a></code> </p>
          </td>
          <td><p>Read libsvm file into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_parquet.html">spark_read_parquet</a></code> </p>
          </td>
          <td><p>Read a Parquet file into a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_source.html">spark_read_source</a></code> </p>
          </td>
          <td><p>Read from a generic source into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_table.html">spark_read_table</a></code> </p>
          </td>
          <td><p>Reads from a Spark Table into a Spark DataFrame.</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_read_text.html">spark_read_text</a></code> </p>
          </td>
          <td><p>Read a Text file into a Spark DataFrame</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_save_table.html">spark_save_table</a></code> </p>
          </td>
          <td><p>Saves a Spark DataFrame as a Spark table</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_table_name.html">spark_table_name</a></code> </p>
          </td>
          <td><p>Generate a Table Name from Expression</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_version.html">spark_version</a></code> </p>
          </td>
          <td><p>Get the Spark Version Associated with a Spark Connection</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_version_from_home.html">spark_version_from_home</a></code> </p>
          </td>
          <td><p>Get the Spark Version Associated with a Spark Installation</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_web.html">spark_web</a></code> </p>
          </td>
          <td><p>Open the Spark web interface</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_csv.html">spark_write_csv</a></code> </p>
          </td>
          <td><p>Write a Spark DataFrame to a CSV</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_jdbc.html">spark_write_jdbc</a></code> </p>
          </td>
          <td><p>Writes a Spark DataFrame into a JDBC table</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_json.html">spark_write_json</a></code> </p>
          </td>
          <td><p>Write a Spark DataFrame to a JSON file</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_parquet.html">spark_write_parquet</a></code> </p>
          </td>
          <td><p>Write a Spark DataFrame to a Parquet file</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_source.html">spark_write_source</a></code> </p>
          </td>
          <td><p>Writes a Spark DataFrame into a generic source</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_table.html">spark_write_table</a></code> </p>
          </td>
          <td><p>Writes a Spark DataFrame into a Spark table</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="spark_write_text.html">spark_write_text</a></code> </p>
          </td>
          <td><p>Write a Spark DataFrame to a Text file</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="sql-transformer.html">ft_sql_transformer</a></code> <code><a href="sql-transformer.html">ft_dplyr_transformer</a></code> </p>
          </td>
          <td><p>Feature Transformation -- SQLTransformer</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="src_databases.html">src_databases</a></code> </p>
          </td>
          <td><p>Show database list</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="tbl_cache.html">tbl_cache</a></code> </p>
          </td>
          <td><p>Cache a Spark Table</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="tbl_change_db.html">tbl_change_db</a></code> </p>
          </td>
          <td><p>Use specific database</p></td>
        </tr><tr>
          <!--  -->
          <td>
            <p><code><a href="tbl_uncache.html">tbl_uncache</a></code> </p>
          </td>
          <td><p>Uncache a Spark Table</p></td>
        </tr>
      </tbody>
      </table>
    </div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#section-all-functions">All functions</a></li>
    </ul>
  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Javier Luraschi, Kevin Kuo, Kevin Ushey, JJ Allaire,  The Apache Software Foundation.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>
