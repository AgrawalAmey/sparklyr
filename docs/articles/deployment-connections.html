<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Tuning Spark connections • sparklyr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">sparklyr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/gallery.html">Gallery</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Guides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/guides-dplyr.html">dplyr</a>
    </li>
    <li>
      <a href="../articles/guides-mllib.html">mllib</a>
    </li>
    <li>
      <a href="../articles/guides-h2o.html">H2O</a>
    </li>
    <li>
      <a href="../articles/guides-extensions.html">Extensions</a>
    </li>
    <li>
      <a href="../articles/guides-caching.html">Caching</a>
    </li>
    <li>
      <a href="../articles/guides-distributed-r.html">Distributed R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Deployment
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/deployment-overview.html">Overview</a>
    </li>
    <li>
      <a href="../articles/deployment-data-lakes.html">Data Lakes</a>
    </li>
    <li>
      <a href="../articles/deployment-cdh.html">Cloudera</a>
    </li>
    <li>
      <a href="../articles/deployment-amazon.html">Amazon</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Reference
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../reference/index.html">Functions</a>
    </li>
    <li>
      <a href="https://github.com/rstudio/cheatsheets/raw/master/source/pdfs/sparklyr.pdf">Cheatsheet</a>
    </li>
    <li>
      <a href="../articles/reference-media.html">Media</a>
    </li>
    <li>
      <a href="../news/index.html">News</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/sparklyr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Tuning Spark connections</h1>
            
          </div>

    
    
<div class="contents">
<div id="hadoop-cluster" class="section level2">
<h2 class="hasAnchor">
<a href="#hadoop-cluster" class="anchor"></a>Hadoop cluster</h2>
<p>Using Spark and R inside a Hadoop based <em>Data Lake</em> is very common at companies. Because Spark is a relatively new technology, there is currently no good way to manage user connections to the Spark service centrally. There are some caps and settings that can be applied, but for most cases there are configurations that the R user will need to customize.</p>
<p>This fact puts the R user in an unusual position of individually deciding how much resources to consume from the cluster, so it is very important to work with the cluster’s administration team or individual to ensure an optimized experience for all.</p>
<p>The <a href="https://spark.apache.org/docs/latest/running-on-yarn.html">Running on YARN</a> page in Spark’s official website is the best place to start for configuration settings reference, please bookmark it. Both, cluster administrators and users can benefit from this document. If Spark is new to the company, the <a href="https://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/">YARN tunning</a> article, courtesy of Cloudera, does a great job at explaining how the Spark/YARN architecture works.</p>
<div id="important-points" class="section level3">
<h3 class="hasAnchor">
<a href="#important-points" class="anchor"></a>Important points</h3>
<ul>
<li><p><strong>Executors are not servers</strong> - In Spark, a server can have multiple <strong>Executors</strong>. Because of how Spark works, it is better to requests multiple smaller executors than a few large executors, the <a href="https://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/">YARN tunning</a> article mentioned above does a great job expanding on this point.</p></li>
<li><p><strong>Spark configuration properties passed by R are just requests</strong> - In most cases, the cluster has the final say regarding the resources apportioned to a given Spark session. Some limits are placed by Spark and some are placed by YARN.</p></li>
<li><p><strong>The cluster overrides ‘silently’</strong> - Many times, no errors are returned when more than the allowed resources are requested, or if an attempt is made to change a setting fixed by the cluster.</p></li>
<li>
<p><strong>Requesting more memory or CPUs for Executors than allowed will return an error</strong> - This is one of the exceptions to the cluster’s ‘silent’ overrides. It will return a message similar to this:</p>
<pre><code>Failed during initialize_connection: java.lang.IllegalArgumentException: Required executor memory (16384+1638 MB) is above the max threshold (8192 MB) of this cluster! Please check the values of 'yarn.scheduler.maximum-allocation-mb' and/or 'yarn.nodemanager.resource.memory-mb'</code></pre>
<p><strong>A cluster’s administrator</strong> is the only person who can make changes to the settings mentioned in the error. If the cluster is supported by a vendor, like Cloudera or Hortonworks, then the change can be made using the cluster’s web UI. Otherwise, changes to those settings are done directly in the <em>yarn-default.xml</em> file.</p>
</li>
</ul>
</div>
<div id="sample-code" class="section level3">
<h3 class="hasAnchor">
<a href="#sample-code" class="anchor"></a>Sample code</h3>
<p>The numbers used in this example should be adjusted to you specific environment. The code below will request 5 executors, and 300 megabytes of memory and 2 cores for each executor.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)

conf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark_config.html">spark_config</a></span>()

conf<span class="op">$</span>spark.executor.memory &lt;-<span class="st"> "300M"</span>
conf<span class="op">$</span>spark.executor.cores &lt;-<span class="st"> </span><span class="dv">2</span>
conf<span class="op">$</span>spark.executor.instances &lt;-<span class="st"> </span><span class="dv">5</span>
conf<span class="op">$</span>spark.dynamicAllocation.enabled &lt;-<span class="st"> "false"</span>

sc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark-connections.html">spark_connect</a></span>(<span class="dt">master =</span> <span class="st">"yarn-client"</span>, 
                    <span class="dt">spark_home =</span> <span class="st">"/usr/lib/spark/"</span>,
                    <span class="dt">version =</span> <span class="st">"1.6.0"</span>,
                    <span class="dt">config =</span> conf)</code></pre></div>
</div>
<div id="code-breakdown" class="section level3">
<h3 class="hasAnchor">
<a href="#code-breakdown" class="anchor"></a>Code breakdown</h3>
<table style="width:94%;" class="table">
<colgroup>
<col width="33%">
<col width="61%">
</colgroup>
<thead><tr class="header">
<th>R</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>conf &lt;- spark_config()</code></td>
<td>Initialize a variable with the contents form <code><a href="../reference/spark_config.html">spark_config()</a></code>
</td>
</tr>
<tr class="even">
<td><code>conf$spark.executor.memory &lt;- "300M"</code></td>
<td>Executor memory is capped by YARN</td>
</tr>
<tr class="odd">
<td><code>conf$spark.executor.cores &lt;- 2</code></td>
<td></td>
</tr>
<tr class="even">
<td><code>conf$spark.executor.instances &lt;- 5</code></td>
<td>Less instances may be allocated based on limits set by the cluster. In this case, the limit is set at 3, so that is the most executors the session gets</td>
</tr>
<tr class="odd">
<td><code>conf$spark.dynamicAllocation.enabled &lt;- "false"</code></td>
<td>Disabling Dynamic Allocation allows the <code>spark.executor.instances</code> to be used</td>
</tr>
<tr class="even">
<td><code>sc &lt;- spark_connect(master = "yarn-client",</code></td>
<td>Use <code>yarn-client</code> as the master</td>
</tr>
<tr class="odd">
<td><code>spark_home = "/usr/lib/spark/",</code></td>
<td>Point <code>spark_home</code> to the cluster’s Spark folder</td>
</tr>
<tr class="even">
<td><code>version = "1.6.2",</code></td>
<td>The version of Spark is restricted to what is available in the cluster</td>
</tr>
<tr class="odd">
<td><code>config = conf)</code></td>
<td>Pass the configuration variable to the <code>config</code> argument</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="images/deployment/connections/yarn-client.jpg">
</div>
</div>
<div id="kerberos" class="section level3">
<h3 class="hasAnchor">
<a href="#kerberos" class="anchor"></a>Kerberos</h3>
<p>There are two options to access a “kerberized” data lake:</p>
<ul>
<li>
<p>Use <em>kinit</em> to get and cache the ticket. After <em>kinit</em> is installed and configured, it can then be used in R via a <code>system()</code> call:p</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system</span>(<span class="st">"echo '&lt;password&gt;' | kinit &lt;username&gt;"</span>)</code></pre></div>
<p>For more information visit this site: <a href="http://directory.apache.org/apacheds/kerberos-ug/4.1-authenticate-kinit.html">Apache - Authenticate with kinit</a></p>
</li>
<li><p>A preferred option may be to use the out-of-the-box integration with Kerberos that the commercial offering of <a href="https://www.rstudio.com/products/rstudio-server-pro/">RStudio Server</a> offers.</p></li>
</ul>
</div>
</div>
<div id="stand-alone-cluster" class="section level2">
<h2 class="hasAnchor">
<a href="#stand-alone-cluster" class="anchor"></a>Stand Alone cluster</h2>
<p>[pending]</p>
</div>
<div id="local" class="section level2">
<h2 class="hasAnchor">
<a href="#local" class="anchor"></a>Local</h2>
<p><code>spakrlyr</code> enables the use of Spark locally in a laptop or desktop.</p>
<div id="sample-code-1" class="section level3">
<h3 class="hasAnchor">
<a href="#sample-code-1" class="anchor"></a>Sample code</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
conf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark_config.html">spark_config</a></span>()

conf<span class="op">$</span><span class="st">`</span><span class="dt">sparklyr.cores.local</span><span class="st">`</span> &lt;-<span class="st"> </span><span class="dv">4</span>
conf<span class="op">$</span><span class="st">`</span><span class="dt">sparklyr.shell.driver-memory</span><span class="st">`</span> &lt;-<span class="st"> "16G"</span>
conf<span class="op">$</span>spark.memory.fraction &lt;-<span class="st"> </span><span class="fl">0.9</span>

sc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark-connections.html">spark_connect</a></span>(<span class="dt">master =</span> <span class="st">"local"</span>, 
                    <span class="dt">version =</span> <span class="st">"2.1.0"</span>,
                    <span class="dt">config =</span> conf)</code></pre></div>
</div>
<div id="code-breakdown-1" class="section level3">
<h3 class="hasAnchor">
<a href="#code-breakdown-1" class="anchor"></a>Code breakdown</h3>
<table style="width:94%;" class="table">
<colgroup>
<col width="33%">
<col width="61%">
</colgroup>
<thead><tr class="header">
<th>R</th>
<th>Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><code>conf &lt;- spark_config()</code></td>
<td>Initialize a variable with the contents form <code><a href="../reference/spark_config.html">spark_config()</a></code>
</td>
</tr>
<tr class="even">
<td><code>conf$sparklyr.cores.local  &lt;- 4</code></td>
<td>If not passed, it will default to the number of all cores in the computer</td>
</tr>
<tr class="odd">
<td><code>conf$sparklyr.shell.driver-memory &lt;- "16G"</code></td>
<td>The session will have one executor, the driver. This means that we can request as much memory as the computer can spare.</td>
</tr>
<tr class="even">
<td><code>conf$spark.memory.fraction &lt;- 0.9</code></td>
<td>Sets the percentage of the memory allocated for the data analysis. It defaults to <em>0.4</em> or 40% of what is requested. The value used in this instance will attempt to set the actual <code>driver-memory</code> to 13.5G, meaning 90% of 16.</td>
</tr>
<tr class="odd">
<td><code>sc &lt;- spark_connect(master = "local",</code></td>
<td></td>
</tr>
<tr class="even">
<td><code>version = "2.1.0",</code></td>
<td>The default version will be set by <code><a href="../reference/spark_install.html">spark_install()</a></code>, but it can be overriden by passing <code>version</code>
</td>
</tr>
<tr class="odd">
<td><code>config = conf)</code></td>
<td>Pass the configuration variable to the <code>config</code> argument</td>
</tr>
</tbody>
</table>
<div class="figure">
<img src="images/deployment/connections/local.jpg">
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#hadoop-cluster">Hadoop cluster</a></li>
      <li><a href="#stand-alone-cluster">Stand Alone cluster</a></li>
      <li><a href="#local">Local</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Javier Luraschi, Kevin Ushey, JJ Allaire,  The Apache Software Foundation.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
