<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Tuning Spark connections • sparklyr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">sparklyr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">Home</a>
</li>
<li>
  <a href="../articles/gallery.html">Gallery</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Guides
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/guides-dplyr.html">dplyr</a>
    </li>
    <li>
      <a href="../articles/guides-mllib.html">mllib</a>
    </li>
    <li>
      <a href="../articles/guides-h2o.html">H2O</a>
    </li>
    <li>
      <a href="../articles/guides-extensions.html">Extensions</a>
    </li>
    <li>
      <a href="../articles/guides-caching.html">Caching</a>
    </li>
    <li>
      <a href="../articles/guides-distributed-r.html">Distributed R</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Deployment
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/deployment-overview.html">Overview</a>
    </li>
    <li>
      <a href="../articles/deployment-data-lakes.html">Data Lakes</a>
    </li>
    <li>
      <a href="../articles/deployment-cdh.html">Cloudera</a>
    </li>
    <li>
      <a href="../articles/deployment-amazon.html">Amazon</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Reference
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../reference/index.html">Functions</a>
    </li>
    <li>
      <a href="https://github.com/rstudio/cheatsheets/raw/master/source/pdfs/sparklyr.pdf">Cheatsheet</a>
    </li>
    <li>
      <a href="../articles/reference-media.html">Media</a>
    </li>
    <li>
      <a href="../news/index.html">News</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/rstudio/sparklyr">
    <span class="fa fa-github"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Tuning Spark connections</h1>
            
          </div>

    
    
<div class="contents">
<div id="spark-clusters" class="section level2">
<h2 class="hasAnchor">
<a href="#spark-clusters" class="anchor"></a>Spark clusters</h2>
<ul>
<li><p><strong>Executors are not servers</strong> - In Spark, a server can have multiple <strong>Executors</strong>. Because of how Spark works, it is better to requests multiple smaller executors than a few large executors, the <a href="https://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/">YARN tunning</a> article mentioned above does a great job expanding on this point.</p></li>
<li><p><strong>Spark configuration properties passed by R are just requests</strong> - In most cases, the cluster has the final say regarding the resources apportioned to a given Spark session. Some limits are placed by Spark and some are placed by YARN.</p></li>
<li><p><strong>The cluster overrides ‘silently’</strong> - Many times, no errors are returned when more than the allowed resources are requested, or if an attempt is made to change a setting fixed by the cluster.</p></li>
</ul>
</div>
<div id="hadoop-cluster" class="section level2">
<h2 class="hasAnchor">
<a href="#hadoop-cluster" class="anchor"></a>Hadoop cluster</h2>
<p>Using Spark and R inside a Hadoop based <em>Data Lake</em> is very common at companies. Because Spark is a relatively new technology, there is currently no good way to manage user connections to the Spark service centrally. There are some caps and settings that can be applied, but for most cases there are configurations that the R user will need to customize.</p>
<p>The <a href="https://spark.apache.org/docs/latest/running-on-yarn.html">Running on YARN</a> page in Spark’s official website is the best place to start for configuration settings reference, please bookmark it. Both, cluster administrators and users can benefit from this document. If Spark is new to the company, the <a href="https://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/">YARN tunning</a> article, courtesy of Cloudera, does a great job at explaining how the Spark/YARN architecture works.</p>
<p>The following are the recommended Spark properties to set when connecting via R:</p>
<ul>
<li><p><strong>spark.executor.memory</strong></p></li>
<li><p><strong>spark.executor.cores</strong></p></li>
<li><p><strong>spark.executor.instances</strong></p></li>
<li><p><strong>spark.dynamicAllocation.enabled</strong></p></li>
</ul>
<div id="example" class="section level3">
<h3 class="hasAnchor">
<a href="#example" class="anchor"></a>Example</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(sparklyr)

conf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark_config.html">spark_config</a></span>()

conf<span class="op">$</span>spark.executor.memory &lt;-<span class="st"> "300M"</span>
conf<span class="op">$</span>spark.executor.cores &lt;-<span class="st"> </span><span class="dv">2</span>
conf<span class="op">$</span>spark.executor.instances &lt;-<span class="st"> </span><span class="dv">3</span>
conf<span class="op">$</span>spark.dynamicAllocation.enabled &lt;-<span class="st"> "false"</span>

sc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark-connections.html">spark_connect</a></span>(<span class="dt">master =</span> <span class="st">"yarn-client"</span>, 
                    <span class="dt">spark_home =</span> <span class="st">"/usr/lib/spark/"</span>,
                    <span class="dt">version =</span> <span class="st">"1.6.0"</span>,
                    <span class="dt">config =</span> conf)</code></pre></div>
<div class="figure">
<img src="images/deployment/connections/yarnclient.png">
</div>
</div>
<div id="executor-memory-error" class="section level3">
<h3 class="hasAnchor">
<a href="#executor-memory-error" class="anchor"></a>Executor memory error</h3>
<p>Requesting more memory or CPUs for Executors than allowed will return an error. This is one of the exceptions to the cluster’s ‘silent’ overrides. It will return a message similar to this:</p>
<pre><code>    Failed during initialize_connection: java.lang.IllegalArgumentException: Required executor memory (16384+1638 MB) is above the max threshold (8192 MB) of this cluster! Please check the values of 'yarn.scheduler.maximum-allocation-mb' and/or 'yarn.nodemanager.resource.memory-mb'</code></pre>
<p><strong>A cluster’s administrator</strong> is the only person who can make changes to the settings mentioned in the error. If the cluster is supported by a vendor, like Cloudera or Hortonworks, then the change can be made using the cluster’s web UI. Otherwise, changes to those settings are done directly in the <em>yarn-default.xml</em> file.</p>
</div>
<div id="kerberos" class="section level3">
<h3 class="hasAnchor">
<a href="#kerberos" class="anchor"></a>Kerberos</h3>
<p>There are two options to access a “kerberized” data lake:</p>
<ul>
<li>
<p>Use <em>kinit</em> to get and cache the ticket. After <em>kinit</em> is installed and configured, it can then be used in R via a <code>system()</code> call:p</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">system</span>(<span class="st">"echo '&lt;password&gt;' | kinit &lt;username&gt;"</span>)</code></pre></div>
<p>For more information visit this site: <a href="http://directory.apache.org/apacheds/kerberos-ug/4.1-authenticate-kinit.html">Apache - Authenticate with kinit</a></p>
</li>
<li><p>A preferred option may be to use the out-of-the-box integration with Kerberos that the commercial offering of <a href="https://www.rstudio.com/products/rstudio-server-pro/">RStudio Server</a> offers.</p></li>
</ul>
</div>
</div>
<div id="standalone-mode" class="section level2">
<h2 class="hasAnchor">
<a href="#standalone-mode" class="anchor"></a>Standalone mode</h2>
<p>The default behavior in Standalone mode is to create one executor per worker. So in a 3 worker node cluster, there will be 3 executors setup. The basic properties that can be set are:</p>
<ul>
<li><p><strong>spark.executor.memory</strong> - The requested memory cannot exceed the actual RAM available.</p></li>
<li><p><strong>spark.memory.fraction</strong> - The default is set to 60% of the requested memory.</p></li>
<li><p><strong>spark.executor.cores</strong> - The requested cores cannot be higher than the cores available in each worker.</p></li>
</ul>
<div id="dynamic-allocation" class="section level3">
<h3 class="hasAnchor">
<a href="#dynamic-allocation" class="anchor"></a>Dynamic Allocation</h3>
<p>If dynamic allocation is disabled, then Spark will attempt to assign all of the available cores evenly across the cluster. The property used is <strong>spark.dynamicAllocation.enabled</strong>.</p>
<p>For example, the Standalone cluster used for this article has 3 worker nodes. Each node has 14.7GB in RAM and 4 cores. This means that there are a total of 12 cores (3 workers with 4 cores) and 44.1GB in RAM (3 workers with 14.7GB in RAM each).</p>
<p>If the <code>spark.executor.cores</code> property is set to 2, and dynamic allocation is disabled, then Spark will spawn 6 executors. The <code>spark.executor.memory</code> property should be set to a level that when the value is multiplied by 6 (number of executors) it will not be over total available RAM. In this case, the value can be safely set to 7GB so that the total memory requested will be 42GB, which is under the available 44.1GB.</p>
</div>
<div id="example-1" class="section level3">
<h3 class="hasAnchor">
<a href="#example-1" class="anchor"></a>Example</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">conf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark_config.html">spark_config</a></span>()
conf<span class="op">$</span>spark.executor.memory &lt;-<span class="st"> "7GB"</span>
conf<span class="op">$</span>spark.memory.fraction &lt;-<span class="st"> </span><span class="fl">0.9</span>
conf<span class="op">$</span>spark.executor.cores &lt;-<span class="st"> </span><span class="dv">2</span>
conf<span class="op">$</span>spark.dynamicAllocation.enabled &lt;-<span class="st"> "false"</span>

sc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark-connections.html">spark_connect</a></span>(<span class="dt">master=</span><span class="st">"spark://master-url:7077"</span>, 
              <span class="dt">version =</span> <span class="st">"2.1.0"</span>,
              <span class="dt">config =</span> conf,
              <span class="dt">spark_home =</span> <span class="st">"/home/ubuntu/spark-2.1.0-bin-hadoop2.7/"</span>)</code></pre></div>
<div class="figure">
<img src="images/deployment/connections/standalone.png">
</div>
</div>
</div>
<div id="local-mode" class="section level2">
<h2 class="hasAnchor">
<a href="#local-mode" class="anchor"></a>Local mode</h2>
<p><code>spakrlyr</code> enables the use of Spark locally in a laptop or desktop. The</p>
<ul>
<li><p><strong>sparklyr.cores.local</strong></p></li>
<li><p><strong>sparklyr.shell.driver-memory</strong></p></li>
<li><p><strong>spark.memory.fraction</strong></p></li>
</ul>
<div id="sample-code" class="section level3">
<h3 class="hasAnchor">
<a href="#sample-code" class="anchor"></a>Sample code</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
conf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark_config.html">spark_config</a></span>()

conf<span class="op">$</span><span class="st">`</span><span class="dt">sparklyr.cores.local</span><span class="st">`</span> &lt;-<span class="st"> </span><span class="dv">4</span>
conf<span class="op">$</span><span class="st">`</span><span class="dt">sparklyr.shell.driver-memory</span><span class="st">`</span> &lt;-<span class="st"> "16G"</span>
conf<span class="op">$</span>spark.memory.fraction &lt;-<span class="st"> </span><span class="fl">0.9</span>

sc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/spark-connections.html">spark_connect</a></span>(<span class="dt">master =</span> <span class="st">"local"</span>, 
                    <span class="dt">version =</span> <span class="st">"2.1.0"</span>,
                    <span class="dt">config =</span> conf)</code></pre></div>
<div class="figure">
<img src="images/deployment/connections/local.png">
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#spark-clusters">Spark clusters</a></li>
      <li><a href="#hadoop-cluster">Hadoop cluster</a></li>
      <li><a href="#standalone-mode">Standalone mode</a></li>
      <li><a href="#local-mode">Local mode</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Javier Luraschi, Kevin Ushey, JJ Allaire,  The Apache Software Foundation.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
